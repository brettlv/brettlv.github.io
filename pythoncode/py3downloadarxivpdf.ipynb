{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T09:14:30.129766+08:00",
     "start_time": "2018-08-03T09:14:29.285073Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding = UTF-8\n",
    "# 爬取html链接中对应的PDF文档,网址：https://blogs.cornell.edu/arxiv/2017/10/16/gw170817/\n",
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "import requests,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T09:30:11.676320+08:00",
     "start_time": "2018-08-03T09:30:11.652663Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# open the url and read\n",
    "def getHtml(url):\n",
    "    page = urllib.request.urlopen(url)\n",
    "    html = page.read()\n",
    "    page.close()\n",
    "    return html\n",
    "# compile the regular expressions and find\n",
    "# all stuff we need\n",
    "def getUrl(html):\n",
    "    reg = r'(1710.\\d+)' #匹配了G176200001\n",
    "    url_re = re.compile(reg)\n",
    "    url_lst = url_re.findall(html.decode('UTF-8')) #返回匹配的数组\n",
    "    return(url_lst)\n",
    "\n",
    "def getFile(url):\n",
    "    timeout=10\n",
    "    file_name = url.split('/')[-1]\n",
    "    u = urllib.request.urlopen(url)\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "'Accept':'text/html;q=0.9,*/*;q=0.8',\n",
    "'Accept-Charset':'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "'Accept-Encoding':'gzip',\n",
    "'Connection':'close',\n",
    "'Referer':None #注意如果依然不能抓取的话，这里可以设置抓取网站的host\n",
    "}\n",
    "\n",
    "    #opener = urllib.request.build_opener()\n",
    "    #opener.addheaders = [headers]\n",
    "    #data = opener.open(url)\n",
    "    #data=requests.get(url)\n",
    "    \n",
    "    block_sz = 8192*16\n",
    "    with open(file_name,\"wb\") as f:\n",
    "        while True:\n",
    "            buffer=u.read(block_sz)\n",
    "            if not buffer:\n",
    "                break\n",
    "            f.write(buffer)      \n",
    "        print (\"Sucessful to download\" + \" \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:01:56.443196Z",
     "start_time": "2017-12-20T09:01:56.435728Z"
    }
   },
   "outputs": [],
   "source": [
    "len(url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T08:59:41.020466Z",
     "start_time": "2017-12-20T08:59:41.016876Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root1_url=  'https://arxiv.org/ftp/arxiv/papers/1710/'\n",
    "root2_url=  'https://arxiv.org/pdf/'\n",
    "\n",
    "#root_url = 'http://pm.zjsti.gov.cn/tempublicfiles/'  #下载地址中相同的部分\n",
    "#raw_url = 'https://blogs.cornell.edu/arxiv/2017/10/16/gw170817/'\n",
    "#raw_url = 'file:///E:/ZjuTH/Documents/pythonCode/pythontest.html'\n",
    "#raw_url = 'https://science.nrao.edu/science/meetings/2018/16th-synthesis-imaging-workshop/16th-synthesis-imaging-workshop-lectures'\n",
    "\n",
    "html = getHtml(raw_url)\n",
    "url_lst = getUrl(html)\n",
    "#print(url_lst)\n",
    "\n",
    "def downpdf(pdfUrl):\n",
    "    filename = pdfUrl.split('/')[-1]\n",
    "    try:\n",
    "        res = requests.get(pdfUrl,stream=True,timeout=10)\n",
    "        if str(res.status_code)[0] == \"4\":\n",
    "            print(str(res.status_code), \":\" , pdfUrl)\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(\"抛出异常：\", pdfUrl)\n",
    "        print(e)\n",
    "        return False\n",
    "    block_sz = 8192*16\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in res.iter_content(chunk_size=102400):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                \n",
    "        #f.write(res.content)    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir('/Users/brettlv')\n",
    "if os.path.exists('/Users/brettlv/GW170817_pdf_download'):\n",
    "    os.chdir('/Users/brettlv/GW170817_pdf_download')\n",
    "else:\n",
    "    os.mkdir('GW170817_pdf_download')\n",
    "    os.chdir(os.path.join(os.getcwd(), 'GW170817_pdf_download'))\n",
    "\n",
    "for url in url_lst[:]:\n",
    "    url1 = root1_url + url+'.pdf'  #形成完整的下载地址\n",
    "    url2 = root2_url + url+'.pdf'\n",
    "    judge=downpdf(url1)\n",
    "    if judge==False:\n",
    "        downpdf(url2)        \n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T10:02:11.065882+08:00",
     "start_time": "2018-08-03T10:02:11.052150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brettlv/blog/brettlv.github.io/pythoncode'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwddir='/Users/brettlv/blog/brettlv.github.io/pythoncode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T10:03:13.945386+08:00",
     "start_time": "2018-08-03T10:03:11.466653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brettlv/16th_synthesis_imaging_workshop\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "import os\n",
    "from lxml.html import parse\n",
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "import requests,time\n",
    "# open the url and read\n",
    "\n",
    "\n",
    "def getHtml(url):\n",
    "    page = urllib.request.urlopen(url)\n",
    "    html = page.read()\n",
    "    page.close()\n",
    "    return html\n",
    "# compile the regular expressions and find\n",
    "# all stuff we need\n",
    "def getUrl(html):\n",
    "    reg = r'(?:href|HREF)=\"?((?:https://)?.+?\\.pdf)' #匹配了\n",
    "    url_re = re.compile(reg)\n",
    "    url_lst = url_re.findall(html.decode('UTF-8')) #返回匹配的数组\n",
    "    return(url_lst)\n",
    "\n",
    "\n",
    "raw_url = 'https://science.nrao.edu/science/meetings/2018/16th-synthesis-imaging-workshop/talks/'\n",
    "#print(url_lst)\n",
    "path='/Users/brettlv/16th_synthesis_imaging_workshop/'\n",
    "isExists = os.path.exists(path)\n",
    "if not isExists:\n",
    "    os.makedirs(path)\n",
    "os.chdir(path)\n",
    "print(os.getcwd())\n",
    "\n",
    "html = getHtml(raw_url)\n",
    "url_lst = getUrl(html)\n",
    "#print(url_lst)\n",
    "\n",
    "def downpdf(pdfUrl):\n",
    "    filename = pdfUrl.split('/')[-1]\n",
    "    try:\n",
    "        res = requests.get(pdfUrl,stream=True,timeout=10)\n",
    "        if str(res.status_code)[0] == \"4\":\n",
    "            print(str(res.status_code), \":\" , pdfUrl)\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(\"抛出异常：\", pdfUrl)\n",
    "        print(e)\n",
    "        return False\n",
    "    block_sz = 8192*16\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in res.iter_content(chunk_size=102400):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "        print(filename,'downloading')        \n",
    "        #f.write(res.content)    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T10:19:58.758116+08:00",
     "start_time": "2018-08-03T10:03:13.947034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brogan_Adv_Cal_1.pdf downloading\n",
      "Brogan_Adv_Cal2.pdf downloading\n",
      "Butler_Solar_System.pdf downloading\n",
      "Chandler_VLASS.pdf downloading\n",
      "Clarke_Low_Frequency.pdf downloading\n",
      "Corsi_16SIW_v2.pdf downloading\n",
      "Deller_Correlators.pdf downloading\n",
      "Deller_VLBI.pdf downloading\n",
      "Friesen_ALMA_OT.pdf downloading\n",
      "Kepley_IIZw40.pdf downloading\n",
      "Li_Protoplanetary_Disks.pdf downloading\n",
      "Marrone_High_redshift.pdf downloading\n",
      "Mason_Mosaicking.pdf downloading\n",
      "McGuire_Astrochemistry.pdf downloading\n",
      "McKinnon_Antennas.pdf downloading\n",
      "MoellenbrockCalibration2018.pdf downloading\n",
      "Perley_Advanced.pdf downloading\n",
      "Perley_Fundamentals.pdf downloading\n",
      "Pihlstrom_Spectral_Line.pdf downloading\n",
      "Rao_Wide_1.pdf downloading\n",
      "Rao_Wide_2.pdf downloading\n",
      "Schinzel_Polarization.pdf downloading\n",
      "Sjouwerman_PlanningVLA_SIW_2018.pdf downloading\n",
      "Taylor_Error_Recognition.pdf downloading\n",
      "Taylor_Image_Analysis.pdf downloading\n",
      "Walker_Array_Design.pdf downloading\n",
      "Wilner_Imaging.pdf downloading\n",
      "Young_Basics.pdf downloading\n",
      "Perley_Geometry_new.pdf downloading\n"
     ]
    }
   ],
   "source": [
    "for url in url_lst[:]:\n",
    "    judge=downpdf(url)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(pwddir)\n",
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
